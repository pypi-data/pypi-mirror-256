Metadata-Version: 2.1
Name: llmtopic
Version: 0.0.3
Summary: A library for extracting topics from text documents using llms.
Author-email: Daniel Klitzke <daniel.klitzke@renumics.com>
Project-URL: Homepage, https://github.com/dani2112/llmtopic
Project-URL: Bug Tracker, https://github.com/dani2112/llmtopic/issues
Classifier: Programming Language :: Python :: 3
Classifier: License :: OSI Approved :: MIT License
Classifier: Operating System :: OS Independent
Requires-Python: >=3.7
Description-Content-Type: text/markdown
Requires-Dist: llama-cpp-python>=0.2.39
Requires-Dist: guidance>=0.1.10
Requires-Dist: sentence-transformers>=2.3.1
Requires-Dist: hnne>=0.1.10
Requires-Dist: tqdm>=4.66.1
Requires-Dist: pyarrow>=15.0.0
Requires-Dist: pandas>=2.2.0

# llmtopic
A library that leverages large language models (llms) for extracting topics from text documents.

## Install
To install for CPU run `pip install llmtopic`.

To install with GPU support run `CMAKE_ARGS="-DLLAMA_CUBLAS=on" pip install llmtopic`.

If you are under Ubuntu and encounter errors regarding a failed build consider upgrading your cuda version to >=12.1. Also, it could be you have to point to the new nvcc version but modifying the install command as follows: `PATH="/usr/local/cuda-12.3/bin:$PATH" CMAKE_ARGS="-DLLAMA_CUBLAS=on" pip install llmtopic`. Note that you of course have to adjsut that to your specific CUDA version.
