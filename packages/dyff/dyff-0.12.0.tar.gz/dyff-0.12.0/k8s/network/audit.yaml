apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: audit-network-policy
  namespace: default
spec:
  podSelector:
    matchLabels:
      app: audit
  policyTypes:
    - Ingress
    - Egress
  # ingress: deny-all
  egress:
    - to:
        - podSelector:
            matchLabels:
              app: api-server
      ports:
        - protocol: TCP
          port: 8080
    - to:
        # Allow kube-dns
        # See: https://github.com/ahmetb/kubernetes-network-policy-recipes/blob/master/11-deny-egress-traffic-from-an-application.md#allowing-dns-traffic
        - namespaceSelector:
            matchLabels:
              kubernetes.io/metadata.name: kube-system
          podSelector:
            matchLabels:
              k8s-app: kube-dns
        # This isn't mentioned anywhere on the Web, but there is a local DNS cache
        # that must be accessible, too (if it is enabled).
        - namespaceSelector:
            matchLabels:
              kubernetes.io/metadata.name: kube-system
          podSelector:
            matchLabels:
              k8s-app: node-local-dns
      ports:
        - port: 53
          protocol: UDP
        - port: 53
          protocol: TCP
    # Next two rules are for GKE Workload Identity
    # See: https://cloud.google.com/kubernetes-engine/docs/concepts/workload-identity#metadata_server
    - to:
        # "For clusters running GKE version 1.21.0-gke.1000 and later..."
        - ipBlock:
            cidr: 169.254.169.252/32
      ports:
        - protocol: TCP
          port: 988
    - to:
        # "For clusters running GKE Dataplane V2..."
        - ipBlock:
            cidr: 169.254.169.254/32
      ports:
        - protocol: TCP
          port: 80
