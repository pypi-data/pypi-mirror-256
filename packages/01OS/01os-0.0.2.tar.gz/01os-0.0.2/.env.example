### SETTINGS
# Copy this file and rename it to ".env" to use it.

# If ALL_LOCAL is False, we'll use OpenAI's services
# else we use whisper.cpp and piper local models
ALL_LOCAL=False
WHISPER_MODEL_NAME="ggml-tiny.en.bin"

# Uncomment to set your OpenAI API key
# OPENAI_API_KEY=sk-...

# For TTS, we use the en_US-lessac-medium voice model by default
# Please change the voice URL and voice name if you wish to use another voice
PIPER_VOICE_URL="https://huggingface.co/rhasspy/piper-voices/resolve/main/en/en_US/lessac/medium/"
PIPER_VOICE_NAME="en_US-lessac-medium.onnx"

# Expose through Ngrok
# Uncomment following line with your Ngrok auth token (https://dashboard.ngrok.com/get-started/your-authtoken)
#NGROK_AUTHTOKEN="AUTH TOKEN"

# If SERVER_START, this is where we'll serve the server.
# If CLIENT_START, this is where the client expects the server to be.
SERVER_URL=ws://localhost:8000/
SERVER_START=True
CLIENT_START=True

# Explicitly set the client type (macos, rpi)
CLIENT_TYPE=auto

# Control where various operations happenâ€” can be `client` or `server`.
CODE_RUNNER=server
TTS_RUNNER=server # If client, audio will be sent over websocket.
STT_RUNNER=client # If server, audio will be sent over websocket.

# Will expose the server publically and display that URL.
SERVER_EXPOSE_PUBLICALLY=False

# Debug level
# LOG_LEVEL=DEBUG
LOG_LEVEL="INFO"