"""Base models for ranking a set of answers generated by LLMs"""
import csv
import json
from abc import abstractmethod
from collections import defaultdict
from typing import Dict, List, Tuple, Type

from ragelo.logger import logger


class AnswerRanker:
    def __init__(
        self,
        name: str,
        output_file: str,
        evaluations_file: str | None = None,
        evaluations: List[Tuple[str, str, str]] | None = None,
        print: bool = False,
        force: bool = False,
        **kwargs,
    ):
        """Base model for dealing with answer rankers
        Args:
            evaluations_file (str): Path to jsonl file containing the answers from
                AnswerEvaluator
            evaluations: List of dictionary containing at least qid, agent_a, agent_b
                and relevant (A, B or C)
            kwargs: Any additional arguments
        """

        if evaluations_file is None and evaluations is None:
            raise ValueError(
                "Either one of evaluations_file or evaluations should be provided"
            )
        if evaluations_file is not None:
            if evaluations is not None:
                logger.warning("Passing both evaluations and evaluations_file")
                logger.warning("Will keep only evaluations_file")
            self.evaluations = self._load_answers(evaluations_file)
        elif evaluations is not None:
            self.evaluations = evaluations
        else:
            raise ValueError("No evaluations found")

        self.ranking: defaultdict = defaultdict(list)
        self.name = name
        self.print = print
        self.force = force
        self.output_file = output_file

    def _load_answers(self, answers_file: str) -> List[Tuple[str, str, str]]:
        evaluations = []
        for line in open(answers_file, "r"):
            data = json.loads(line)
            agent_a = data["agent_a"]
            agent_b = data["agent_b"]
            relevant = data["relevant"]
            evaluations.append((agent_a, agent_b, relevant))
        return evaluations

    @abstractmethod
    def evaluate(self):
        """Compute score for each agent"""
        raise NotImplementedError

    @abstractmethod
    def get_agents_ratings(self) -> Dict[str, float]:
        """Returns the score of all players"""
        raise NotImplementedError

    def print_ranking(self):
        if self.print:
            logger.info(
                f"-------[bold white] Agent Scores by {self.name} [/bold white]-------"
            )

            for agent, rating in sorted(
                self.get_agents_ratings().items(), key=lambda x: x[1], reverse=True
            ):
                logger.info(f"[bold white]{agent:<15}[/bold white]: {rating:.1f}")
        with open(self.output_file, "w") as f:
            writer = csv.writer(f)
            writer.writerow(["agent", "score"])
            for agent, rating in sorted(
                self.get_agents_ratings().items(), key=lambda x: x[1], reverse=True
            ):
                writer.writerow([agent, rating])


class AnswerRankerFactory:
    registry: Dict[str, Type[AnswerRanker]] = {}

    @classmethod
    def register(cls, name: str):
        def inner_wrapper(wrapped_class: Type[AnswerRanker]):
            if name in cls.registry:
                logger.warning(f"Overwriting {name} in Answer Evaluator registry")
            cls.registry[name.lower()] = wrapped_class
            return wrapped_class

        return inner_wrapper

    @classmethod
    def create(cls, name: str, **kwargs) -> AnswerRanker:
        if name.lower() not in cls.registry:
            raise ValueError(f"{name} not in registry")
        return cls.registry[name.lower()](name=name, **kwargs)
