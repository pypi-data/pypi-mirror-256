{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/bleu/ai/deeprhythm/src')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading model weights...\n",
      "Model weights downloaded successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bleu/anaconda3/envs/autoawq/lib/python3.10/site-packages/torch/nn/modules/conv.py:459: UserWarning: Using padding='same' with even kernel lengths and odd dilation may require a zero-padded copy of the input be created (Triggered internally at /opt/conda/conda-bld/pytorch_1682343995026/work/aten/src/ATen/native/Convolution.cpp:1003.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "129.5"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.deeprhythm.model.predictor import DeepRhythmPredictor\n",
    "\n",
    "model = DeepRhythmPredictor()\n",
    "model.predict('data/VERIZON.flac')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "dataset_dir = '/media/bleu/bulkdata2/deeprhythmdata'\n",
    "\n",
    "full_df = pd.read_csv(os.path.join(dataset_dir, 'manifest.csv'))\n",
    "full_df.drop(columns=[col for col in full_df.columns if 'Unnamed' in col], inplace=True)\n",
    "full_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Splitting the full dataframe into separate dataframes for each source\n",
    "df_slakh = full_df[full_df['source'] == 'slakh']\n",
    "df_fma = full_df[full_df['source'] == 'fma']\n",
    "df_giantsteps = full_df[full_df['source'] == 'giantsteps']\n",
    "df_ballroom = full_df[full_df['source'] == 'ballroom']\n",
    "df_arcbeam = full_df[full_df['source'] == 'arcbeam']\n",
    "df_yarr = full_df[full_df['source'] == 'yarr']\n",
    "len(df_slakh), len(df_fma), len(df_giantsteps), len(df_ballroom), len(df_arcbeam), len(df_yarr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataframe_direct(df, proportions):\n",
    "    \"\"\"\n",
    "    Shuffle and split a DataFrame into three parts based on given proportions.\n",
    "\n",
    "    Parameters:\n",
    "    - df: The pandas DataFrame to split.\n",
    "    - proportions: A list or tuple of three proportions. The sum must be equal to 1.\n",
    "\n",
    "    Returns:\n",
    "    - Three pandas DataFrames corresponding to the given proportions.\n",
    "    \"\"\"\n",
    "    train_ratio, test_ratio, validate_ratio = proportions\n",
    "    total_ratio = train_ratio + test_ratio + validate_ratio\n",
    "    assert abs(total_ratio - 1) < 1e-6, \"Ratios must sum to 1\"\n",
    "    # Shuffle the DataFrame\n",
    "    df_shuffled = df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "    # Calculate split indices\n",
    "    first_split = int(proportions[0] * len(df))\n",
    "    second_split = first_split + int(proportions[1] * len(df))\n",
    "\n",
    "    # Split the DataFrame\n",
    "    df_first = df_shuffled.iloc[:first_split]\n",
    "    df_second = df_shuffled.iloc[first_split:second_split]\n",
    "    df_third = df_shuffled.iloc[second_split:]\n",
    "\n",
    "    return df_first, df_second, df_third"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes = [df_slakh, df_arcbeam, df_giantsteps, df_ballroom, df_yarr]\n",
    "full_train, full_val, full_test = pd.DataFrame(), pd.DataFrame(), pd.DataFrame()\n",
    "\n",
    "for df in dataframes:\n",
    "    train, val, test = split_dataframe_direct(df, (0.8, 0.1, 0.1))\n",
    "    full_train = pd.concat([full_train, train])\n",
    "    full_val = pd.concat([full_val, val])\n",
    "    full_test = pd.concat([full_test, test])\n",
    "\n",
    "full_train.to_csv(os.path.join(dataset_dir, 'train.csv'))\n",
    "full_val.to_csv(os.path.join(dataset_dir, 'val.csv'))\n",
    "full_test.to_csv(os.path.join(dataset_dir, 'test.csv'))\n",
    "len(full_train), len(full_val), len(full_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "autoawq",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
