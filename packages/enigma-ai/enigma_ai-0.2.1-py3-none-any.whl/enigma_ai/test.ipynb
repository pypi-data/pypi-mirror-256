{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Required FLOPs': 6000000000.0, 'Actual FLOPs': 1125.08928}\n",
      "Expected Perplexity: 0.7488900210846068\n"
     ]
    }
   ],
   "source": [
    "import enigma_ai.cost.resources as res\n",
    "import enigma_ai.cost.performance as perf\n",
    "\n",
    "gpus = [\n",
    "    res.GPUTensorCoreSpec(name=\"A100\", clock_rate_ghz=1.41, \n",
    "                        num_tensor_cores=6912),\n",
    "    res.GPUTensorCoreSpec(name=\"V100\", clock_rate_ghz=1.53, \n",
    "                        num_tensor_cores=5120),\n",
    "]\n",
    "gpu_specs = res.GPUSpec(name=\"NVIDIA\", architecture=\"Ampere\", gpus=gpus)\n",
    "\n",
    "# Define hardware specifications\n",
    "hardware = res.HardwareSpec(gpus=[gpu_specs])\n",
    "\n",
    "# Define experiment specifications\n",
    "spec = res.ExperimentSpec(model_params=1e9, dataset=1e12, \n",
    "                        hardware=hardware, precision=\"fp32\", \n",
    "                        hours_trained=1.0)\n",
    "\n",
    "# Calculate compute cost\n",
    "compute = res.calculate_compute_cost(spec)\n",
    "print(compute)\n",
    "\n",
    "\n",
    "\n",
    "############################################\n",
    "# Performance\n",
    "\n",
    "# Select a Scaling Factor (Model Size, Dataset Size, or LoRa Parameters)\n",
    "scaling_factor = \"Model Size\"\n",
    "\n",
    "#Select parameters for the scaling factor\n",
    "model_size = 1e9 # 1 billion parameters\n",
    "dataset_size = 1e12 # 1 trillion samples\n",
    "\n",
    "\n",
    "scaling_params = perf.estimate_finetuning_performance(\n",
    "    scaling_factor,\n",
    "    model_size=model_size,\n",
    "    dataset_size=dataset_size,\n",
    ")\n",
    "\n",
    "print(f'Expected Perplexity: {scaling_params[\"L\"]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enigma_ai.cost import performance\n",
    "\n",
    "scalling_factor = 'Dataset Size'\n",
    "model_size = 10**6\n",
    "dataset_size = 10**6\n",
    "performance.estimate_finetuning_performance(scalling_factor, model_size, dataset_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enigma_ai.data import scrape\n",
    "\n",
    "# Set up your GitHub API token\n",
    "github_token = 'your_github_api_token'\n",
    "\n",
    "# Define your search query and parameters\n",
    "search_term = 'pentest'\n",
    "max_results = 100\n",
    "filename = 'fetched_repos.csv'\n",
    "\n",
    "# Fetch repositories matching the query\n",
    "repos_df = scrape.fetch_repos(github_token, max_results, filename, search_term, min_stars=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enigma_ai.data import process\n",
    "import pandas as pd\n",
    "\n",
    "# Load the previously fetched repository data\n",
    "filename = 'fetched_repos.csv'\n",
    "repos_df = pd.read_csv(filename)\n",
    "\n",
    "#Limit the number of repositories to process\n",
    "repos_df = repos_df.head(1)\n",
    "\n",
    "# Extract code files from the repositories\n",
    "repos_with_code = process.extract_code_from_repos(repos_df, filename, github_token)\n",
    "\n",
    "#Print the first 1000 characters of the README.md file of the first repository\n",
    "print(repos_with_code['code'].values[0]['Markdown']['README.md'][:1000])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enigma_ai.finetuning import train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "amazon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
